{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38fa45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import ml_collections\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os\n",
    "import torch\n",
    "import scipy.io\n",
    "import random\n",
    "from src2.utilities import *\n",
    "from src2.utilities_NSPDE import dataloader_nspde_2d, train_nspde\n",
    "from src2.fusion_model import Fusion_NSPDE\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95ac0ae",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950173eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dir = 'configs/example.yaml'\n",
    "with open(config_dir) as file:\n",
    "    config = ml_collections.ConfigDict(yaml.safe_load(file))\n",
    "\n",
    "# Set random seed\n",
    "seed = config.seed\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "if (config.device ==\n",
    "        \"cuda\" and torch.cuda.is_available()):\n",
    "    config.update({\"device\": \"cuda:0\"}, allow_val_change=True)\n",
    "else:\n",
    "    config.update({\"device\": \"cpu\"}, allow_val_change=True)\n",
    "DEVICE = torch.device(config.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f435aac",
   "metadata": {},
   "source": [
    "# Load and Processing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49667856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Noise W shape:  torch.Size([1500, 32, 32, 201])\n",
      "Raw Solution Sol shape:  torch.Size([1500, 32, 32, 201])\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 3\n",
    "T_TRAIN_STEPS = 201\n",
    "N_TOTAL_SAMPLES = 1500\n",
    "# Check training data\n",
    "data_training = scipy.io.loadmat(r\"data/public_data.mat\")\n",
    "W_raw = torch.tensor(data_training['W']).float()\n",
    "Sol_raw = torch.tensor(data_training['sol']).float()\n",
    "print('Raw Noise W shape: ', W_raw.shape)  \n",
    "print('Raw Solution Sol shape: ', Sol_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TOTAL_SAMPLES = 1500\n",
    "N_TRAIN = 1300\n",
    "N_VAL = 100\n",
    "N_TEST = 100 \n",
    "SEED_SPLIT = 42 \n",
    "torch.manual_seed(SEED_SPLIT)\n",
    "\n",
    "indices = torch.randperm(N_TOTAL_SAMPLES)\n",
    "idx_train = indices[:N_TRAIN]\n",
    "idx_val = indices[N_TRAIN:N_TRAIN + N_VAL]\n",
    "idx_test = indices[N_TRAIN + N_VAL:]\n",
    "\n",
    "W_train_raw = W_raw[idx_train]\n",
    "Sol_train_raw = Sol_raw[idx_train]\n",
    "\n",
    "W_val_raw = W_raw[idx_val]\n",
    "Sol_val_raw = Sol_raw[idx_val]\n",
    "\n",
    "W_test_raw = W_raw[idx_test]\n",
    "Sol_test_raw = Sol_raw[idx_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdff56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataloader(W, Sol, batch_size, shuffle):\n",
    "    \n",
    "    u0 = Sol[..., 0] # [N, 32, 32]\n",
    "    u_label = Sol       # [N, 32, 32, 201]\n",
    "    xi_data = W         # [N, 32, 32, 201]\n",
    "    \n",
    "    return DataLoader(TensorDataset(u0, xi_data, u_label), batch_size=batch_size, shuffle=shuffle, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd51427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val/Test Dataloaders created: 1300/100/100 samples.\n"
     ]
    }
   ],
   "source": [
    "train_loader = create_dataloader(W_train_raw, Sol_train_raw, BATCH_SIZE, shuffle=True)\n",
    "val_loader = create_dataloader(W_val_raw, Sol_val_raw, BATCH_SIZE, shuffle=False)\n",
    "test_loader = create_dataloader(W_test_raw, Sol_test_raw, BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"Train/Val/Test Dataloaders created: {N_TRAIN}/{N_VAL}/{N_TEST} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea98ef3",
   "metadata": {},
   "source": [
    "# Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6ee082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pure U0 Indices: [1, 3, 4]\n",
      "Xi/Mixed Indices: [0, 2, 5, 6, 7, 8, 9]\n",
      "DLR Split Mode ACTIVE. U_feat: 6, Xi_feat: 15\n",
      "Fusion_NSPDE(\n",
      "  (dlr_encoder): LearnableDLREncoder(\n",
      "    (physics_engine): ParabolicIntegrate_2d()\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=10, out_features=32, bias=True)\n",
      "      (1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
      "      (2): GELU(approximate='none')\n",
      "      (3): Linear(in_features=32, out_features=1, bias=True)\n",
      "      (4): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (norm_u): InstanceNorm3d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (norm_xi): InstanceNorm3d(14, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
      "  (lift): Linear(in_features=1, out_features=32, bias=True)\n",
      "  (spde_func): SPDEFunc1d(\n",
      "    (net_F): Sequential(\n",
      "      (0): Conv2d(38, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "      (2): GLU(dim=1)\n",
      "      (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (net_G): Sequential(\n",
      "      (0): Conv2d(52, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "      (2): GLU(dim=1)\n",
      "      (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (readout): Sequential(\n",
      "    (0): Linear(in_features=32, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (solver): DiffeqSolver(\n",
      "    (spde_func): SPDEFunc1d(\n",
      "      (net_F): Sequential(\n",
      "        (0): Conv2d(38, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "        (2): GLU(dim=1)\n",
      "        (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (net_G): Sequential(\n",
      "        (0): Conv2d(52, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "        (2): GLU(dim=1)\n",
      "        (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (cde): ControlledODE(\n",
      "      (spde_func): SPDEFunc1d(\n",
      "        (net_F): Sequential(\n",
      "          (0): Conv2d(38, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "          (2): GLU(dim=1)\n",
      "          (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "        (net_G): Sequential(\n",
      "          (0): Conv2d(52, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (1): GroupNorm(4, 128, eps=1e-05, affine=True)\n",
      "          (2): GLU(dim=1)\n",
      "          (3): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "Hybrid Model initialized using diffeq.\n",
      "DLR Encoder is ACTIVE. Context channels: 20\n"
     ]
    }
   ],
   "source": [
    "# === Model HYBRID (DLR + NSPDE) ===\n",
    "\n",
    "HIDDEN_CHANNELS = 32  \n",
    "MODES_X = 16          \n",
    "MODES_Y = 16         \n",
    "N_ITER_SOLVER = 1     \n",
    "SOLVER_MODE = 'diffeq' \n",
    "\n",
    "T_points = torch.linspace(0, 0.020, 201).to(DEVICE) \n",
    "X_points = torch.linspace(0, 1, 32).to(DEVICE)\n",
    "Y_points = torch.linspace(0, 1, 32).to(DEVICE)\n",
    "\n",
    "# 2. Initialize the Model with the DLR Encoder\n",
    "model = Fusion_NSPDE(\n",
    "    dim=2, \n",
    "    in_channels=1, \n",
    "    noise_channels=1, \n",
    "    hidden_channels=HIDDEN_CHANNELS,\n",
    "    n_iter=N_ITER_SOLVER, \n",
    "    modes1=MODES_X, \n",
    "    modes2=MODES_Y, \n",
    "    solver=SOLVER_MODE,\n",
    "  \n",
    "    T_points=T_points,\n",
    "    X_points=X_points,\n",
    "    Y_points=Y_points,\n",
    "    device=DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)\n",
    "\n",
    "print(f\"Hybrid Model initialized using {SOLVER_MODE}.\")\n",
    "if hasattr(model, 'use_dlr') and model.use_dlr:\n",
    "    print(f\"DLR Encoder is ACTIVE. Context channels: {model.context_channels}\")\n",
    "else:\n",
    "    print(\"WARNING: DLR Encoder is NOT active.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe6c0c8",
   "metadata": {},
   "source": [
    "# Load Check Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d019f0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found checkpoint: src2/best_fusion_model_trained.pth\n",
      "\n",
      "Loading Status:\n",
      "✅ Loaded 58 layers successfully.\n",
      "\n",
      "Mô hình đã sẵn sàng để train tiếp (Fine-tuning).\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = r'src/best_fusion_model_trained.pth' \n",
    "\n",
    "if os.path.exists(CHECKPOINT_PATH):\n",
    "    print(f\"Found checkpoint: {CHECKPOINT_PATH}\")\n",
    "    state_dict = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    model_dict = model.state_dict() \n",
    "    \n",
    "    pretrained_dict = {}\n",
    "    keys_loaded = []\n",
    "    keys_skipped = []\n",
    "\n",
    "    for k, v in state_dict.items():\n",
    "        if k in model_dict:\n",
    "            \n",
    "            if v.shape == model_dict[k].shape:\n",
    "                pretrained_dict[k] = v\n",
    "                keys_loaded.append(k)\n",
    "            else:\n",
    "                keys_skipped.append(f\"{k} (Shape mismatch: ckpt {v.shape} vs model {model_dict[k].shape})\")\n",
    "        else:\n",
    "            keys_skipped.append(f\"{k} (Not found in current model)\")\n",
    "\n",
    "    # Update model state\n",
    "    model_dict.update(pretrained_dict)\n",
    "    \n",
    "    model.load_state_dict(model_dict, strict=False)\n",
    "    \n",
    "    print(f\"\\nLoading Status:\")\n",
    "    print(f\"✅ Loaded {len(keys_loaded)} layers successfully.\")\n",
    "    if len(keys_skipped) > 0:\n",
    "        print(f\"⚠️ Skipped {len(keys_skipped)} layers:\")\n",
    "        for msg in keys_skipped[:5]:\n",
    "            print(f\"   - {msg}\")\n",
    "            \n",
    "    print(\"\\nThe model is ready for further training (fine-tuning).\")\n",
    "else:\n",
    "    print(f\"No checkpoint found at {CHECKPOINT_PATH}. Training will start from scratch.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5400c1f7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfa5ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bắt đầu huấn luyện mô hình...\n",
      "Training interrupted explicitly.\n",
      "Huấn luyện hoàn tất. Tải mô hình tốt nhất.\n"
     ]
    }
   ],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 20\n",
    "PRINT_EVERY = 1\n",
    "\n",
    "myloss = LpLoss(size_average=False) \n",
    "\n",
    "print(\"\\nStarting model training…\")\n",
    "\n",
    "model_trained, losses_train, losses_val = train_nspde(\n",
    "    model=model, \n",
    "    train_loader=train_loader, \n",
    "    test_loader=val_loader, \n",
    "    device=DEVICE, \n",
    "    myloss=myloss, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    plateau_patience=2,      \n",
    "    plateau_terminate=20,     \n",
    "    scheduler_gamma=0.5,      \n",
    "    print_every=PRINT_EVERY,\n",
    "    checkpoint_file=CHECKPOINT_FILE\n",
    ")\n",
    "\n",
    "print(\"Training completed. Loading the best model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
